Core Functions in JAX backend
=============================

.. currentmodule:: brainpy.math.jax
.. automodule:: brainpy.math.jax


Compilations
------------

.. autosummary::
    :toctree: generated/

    jit
    vmap
    pmap


Gradients
---------

.. autosummary::
    :toctree: generated/

    grad
    value_and_grad


Variables
---------

.. autosummary::
    :toctree: generated/

    Variable
    TrainVar
    Parameter


Activation Functions
--------------------

.. autosummary::
    :toctree: generated/

    celu
    elu
    gelu
    glu
    hard_tanh
    hard_sigmoid
    hard_silu
    hard_swish
    leaky_relu
    log_sigmoid
    log_softmax
    one_hot
    normalize
    relu
    relu6
    sigmoid
    soft_sign
    softmax
    softplus
    silu
    swish
    selu
    tanh

