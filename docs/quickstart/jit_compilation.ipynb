{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Just-In-Time Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea behind BrainPy is the Just-In-Time (JIT) compilation. JIT compilation enables your Python code to be compiled into machine code \"just-in-time\" for execution. Subsequently, such transformed code can run at native machine code speed!\n",
    "\n",
    "Excellent JIT compilers such as [JAX](https://github.com/google/jax) and [Numba](https://github.com/numba/numba) are provided in Python. However, they are designed to work only on pure Python functions: all the input data is passed through the function parameters, all the results are output through the function results. While, the essence of Python is object-oriented programming (OOP) based on ``class``. OOP makes the programming more flexible, modular, and re-usable. In BrainPy, we relieve these constraints and enables users to JIT a class object without the preformance loss. \n",
    "\n",
    "In this section, we will talk about the JIT compilation in BrainPy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import brainpy as bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIT in Numba and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Numba](https://github.com/numba/numba) is specialized to optimize your native Python codes such like functions, NumPy arrays, loops and condition controls. It is a cross-platform library which can run on Windows, Linux, macOS, etc. The most wonderful thing is that numba can JIT compile your native Python loops (``for`` or ``while`` syntaxs) and condition controls (``if ... else ...``). This means that it supports your intutive Python programming. \n",
    "\n",
    "However, Numba is a lightweight JIT compiler, and is just suitable for small network models. For large networks, the parallel performance is poor. Futhermore, numba doesn't support `one code runs on multiple devices`. Same code cannot run on GPU targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[JAX](https://github.com/google/jax) is a rising-star JIT compiler in Python scientific computing. It uses [XLA](https://www.tensorflow.org/xla) to JIT compile and run your NumPy programs. Same code can be deployed onto CPUs, GPUs and TPUs. Moreover, JAX supports automatic differentiation, which means you can train models through back-propagation. JAX prefers large network models, and has excellent parallel performance. \n",
    "\n",
    "However, JAX has intrinsic overhead, and is not suitable to run small networks. Moreover, JAX only supports Linux and macOS platforms. Windows users must install JAX on [WSL](https://docs.microsoft.com/en-us/windows/wsl/about) or compile JAX from source. Further, the coding in JAX is not very intutive. For example, \n",
    "\n",
    "- Doesn't support in-place mutating updates of arrays, like ``x[i] += y``, instead you should use `x = jax.ops.index_update(x, i, y)`\n",
    "- Doesn't support JIT compilation of your native loops and conditions, like\n",
    "```python\n",
    "arr = np.zeros(5)\n",
    "for i in range(arr.shape[0]):\n",
    "    arr[i] += 2.\n",
    "    if i % 2 == 0:\n",
    "        arr[i] += 1.\n",
    "```\n",
    "instead you should use \n",
    "```python\n",
    "arr = np.zeros(5)\n",
    "def loop_body(i, acc_arr):\n",
    "    arr1 = ops.index_update(acc_arr, i, acc_arr[i] + 2.)\n",
    "    return jax.lax.cond(i % 2 == 0, \n",
    "                        arr1,\n",
    "                        lambda arr1: ops.index_update(arr1, i, arr1[i] + 1),\n",
    "                        arr1,\n",
    "                        lambda arr1: arr1)\n",
    "arr = jax.lax.fori_loop(0, arr.shape[0], loop_body, arr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, both frameworks have poor support on class objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BrainPy `math` module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain an *intutive*, *flexible* and *high-performance* framework for brain modeling, in [BrainPy](https://github.com/PKU-NIP-Lab/BrainPy), we want to combine the advantages of both compilers together, and try to overcome the gotchas of each framework as much as possible (although we have not finished it). Specifically, we provide [BrainPy math module](../apis/math.rst) for:\n",
    "\n",
    "- flexible switch between NumPy and JAX backends\n",
    "- unified numpy-like array operations \n",
    "- unified ``ndarray`` data structure which supports in-place update\n",
    "- unified ``random`` APIs\n",
    "- powerful ``jit()`` compilation which supports functions and class objects both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can switch to different backends by using ``brainpy.math.use_backend``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numpy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch to NumPy backend\n",
    "bp.math.use_backend('numpy')\n",
    "\n",
    "bp.math.get_backend_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jax'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch to JAX backend\n",
    "bp.math.use_backend('jax')\n",
    "\n",
    "bp.math.get_backend_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the backend switch, the APIs in ``brainpy.math`` is much similar to APIs in original ``numpy``. The detailed comparison please see the [Comparison Table](../apis/math/comparison.rst). \n",
    "\n",
    "For example, the **array creation** APIs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.zeros((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[1, 2],\n",
       "                      [3, 4]], dtype=int32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = bp.math.array([[1,2], [3,4]])\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **array manipulation** APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(4, dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([1, 1, 2, 2, 3, 3, 4, 4], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.repeat(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[1, 1, 2, 2],\n",
       "                      [3, 3, 4, 4]], dtype=int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.repeat(x, 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **random numbers** generation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[0.15193117, 0.7006848 , 0.75320196, 0.29045963, 0.7425157 ],\n",
       "                      [0.18510342, 0.9365095 , 0.02459204, 0.2899201 , 0.1062901 ],\n",
       "                      [0.31897604, 0.14713216, 0.0075345 , 0.60187805, 0.293056  ]],            dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.random.random((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[-2.5946703 , -0.44657612,  1.4826825 , -3.1162384 ,\n",
       "                        0.60915095],\n",
       "                      [-0.6821795 , -0.7344547 ,  0.24855301, -1.627654  ,\n",
       "                        1.7101754 ]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = bp.math.random.normal(loc=0.0, scale=2.0, size=(2, 5))\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **linear algebra** functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[ -3.9590292,  -1.9154855,   1.9797885,  -6.3715463,\n",
       "                         4.029502 ],\n",
       "                      [-10.512729 ,  -4.277547 ,   5.44226  , -15.859331 ,\n",
       "                         8.668155 ]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(JaxArray(DeviceArray([-0.37228107+0.j,  5.3722816 +0.j], dtype=complex64)),\n",
       " JaxArray(DeviceArray([[-0.8245648 +0.j, -0.41597357+0.j],\n",
       "                       [ 0.56576747+0.j, -0.9093767 +0.j]], dtype=complex64)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.linalg.eig(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Discrete Fourier Transform** functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([ 3.2584137e-07+3.1786513e-08j,  8.0000000e+00+4.8023384e-07j,\n",
       "                      -3.2584137e-07+3.1786513e-08j, -1.6858739e-07+3.1786506e-08j,\n",
       "                      -3.8941437e-07-2.0663207e-07j,  2.3841858e-07-1.9411573e-07j,\n",
       "                       3.8941437e-07-2.0663207e-07j,  1.6858739e-07+3.1786506e-08j],            dtype=complex64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.fft.fft(bp.math.exp(2j * bp.math.pi * bp.math.arange(8) / 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([ 1.+0.j,  0.+1.j, -1.+0.j,  0.-1.j], dtype=complex64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.fft.ifft(bp.math.array([0, 4, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full list of API implementation please see the [Comparison Table](../apis/math/comparison.rst)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIT compilation in BrainPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with Numba and JAX, BrainPy supports JIT compilation for **functions**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in JAX backend, we implementat a ``selu`` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.math.use_backend('jax')\n",
    "\n",
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * bp.math.where(x > 0, x, alpha * bp.math.exp(x) - alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What need you to do is to simply pass the function into the [bp.math.jit()](../apis/math/generated/brainpy.math.jax.jit.rst):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selu_jit = bp.math.jit(selu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bp.math.random.random((1000000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.69 ms ± 103 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 µs ± 13.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit selu_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, in NumPy backend, we can also compare the non-jitted ``selu`` function and the jitted one which wrapped by [bp.math.jit()](../apis/math/generated/brainpy.math.numpy.jit.rst):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.math.use_backend('numpy')\n",
    "\n",
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * bp.math.where(x > 0, x, alpha * bp.math.exp(x) - alpha)\n",
    "\n",
    "selu_jit = bp.math.jit(selu)\n",
    "\n",
    "x = bp.math.random.random((1000000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.26 ms ± 173 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit selu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.64 ms ± 117 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "selu_jit(x)\n",
    "\n",
    "%timeit selu_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in BrainPy, JIT compilation can be carried on the objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainpy",
   "language": "python",
   "name": "brainpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
