{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Just-In-Time Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea behind BrainPy is the Just-In-Time (JIT) compilation. JIT compilation enables your Python code to be compiled into machine code \"just-in-time\" for execution. Subsequently, such transformed code can run at native machine code speed!\n",
    "\n",
    "Excellent JIT compilers such as [JAX](https://github.com/google/jax) and [Numba](https://github.com/numba/numba) are provided in Python. However, they are designed to work only on pure Python functions. While, in computational neuroscience, most models have too many parameters and variables, it's hard to manage and control model logic by only using functions. On the contrary, object-oriented programming (OOP) based on ``class`` in Python will make your coding more readable, controlable, flexible and modular. Therefore, it is necessary to support JIT compilation on class objects for programming in brain modeling. \n",
    "\n",
    "Here, in BrainPy, we provide JIT compilation interface for class objects, built on the top of JAX and Numba. In this section, we will talk about this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import brainpy as bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIT in Numba and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Numba](https://github.com/numba/numba) is specialized to optimize your native NumPy codes, including NumPy arrays, loops and condition controls, etc. It is a cross-platform library which can run on Windows, Linux, macOS, etc. The most wonderful thing is that numba can just-in-time compile your native Python loops (``for`` or ``while`` syntaxs) and condition controls (``if ... else ...``). This means that it supports your intutive Python programming. \n",
    "\n",
    "However, Numba is a lightweight JIT compiler, and is just suitable for small network models. For large networks, the parallel performance is poor. Futhermore, numba doesn't support `one code runs on multiple devices`. Same code cannot run on GPU targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[JAX](https://github.com/google/jax) is a rising-star JIT compiler in Python scientific computing. It uses [XLA](https://www.tensorflow.org/xla) to JIT compile and run your NumPy programs. Same code can be deployed onto CPUs, GPUs and TPUs. Moreover, JAX supports automatic differentiation, which means you can train models through back-propagation. JAX prefers large network models, and has excellent parallel performance. \n",
    "\n",
    "However, JAX has intrinsic overhead, and is not suitable to run small networks. Moreover, JAX only supports Linux and macOS platforms. Windows users must install JAX on [WSL](https://docs.microsoft.com/en-us/windows/wsl/about) or compile JAX from source. Further, the coding in JAX is not very intutive. For example, \n",
    "\n",
    "- Doesn't support in-place mutating updates of arrays, like ``x[i] += y``, instead you should use `x = jax.ops.index_update(x, i, y)`\n",
    "- Doesn't support JIT compilation of your native loops and conditions, like\n",
    "```python\n",
    "arr = np.zeros(5)\n",
    "for i in range(arr.shape[0]):\n",
    "    arr[i] += 2.\n",
    "    if i % 2 == 0:\n",
    "        arr[i] += 1.\n",
    "```\n",
    "instead you should use \n",
    "```python\n",
    "arr = np.zeros(5)\n",
    "def loop_body(i, acc_arr):\n",
    "    arr1 = ops.index_update(acc_arr, i, acc_arr[i] + 2.)\n",
    "    return jax.lax.cond(i % 2 == 0, \n",
    "                        arr1,\n",
    "                        lambda arr1: ops.index_update(arr1, i, arr1[i] + 1),\n",
    "                        arr1,\n",
    "                        lambda arr1: arr1)\n",
    "arr = jax.lax.fori_loop(0, arr.shape[0], loop_body, arr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, both frameworks have poor support on class objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIT compilation in BrainPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain an *intutive*, *flexible* and *high-performance* framework for brain modeling, in [BrainPy](https://github.com/PKU-NIP-Lab/BrainPy), we want to combine the advantages of both compilers together, and try to overcome the gotchas of each framework as much as possible (although we have not finished it). \n",
    "\n",
    "Specifically, we provide [BrainPy math module](../apis/math.rst) for \n",
    "\n",
    "- flexible switch between NumPy/Numba and JAX backends\n",
    "- unified numpy-like array operations \n",
    "- unified ``ndarray`` data structure which supports in-place update\n",
    "- unified ``random`` APIs\n",
    "- powerful ``jit()`` compilation which supports functions and class objects both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend Switch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantages and disadvantages of Numba and JAX are listed in above. We support them both for different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are coding a small network model, NumPy/Numba backend may be very suitable for you. You can switch to this backend by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numpy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch to NumPy backend\n",
    "bp.math.use_backend('numpy')\n",
    "\n",
    "bp.math.get_backend_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, \"numpy\" is the default backend used in BrainPy. However, if you are coding a large-scale network model, or try to run on GPUs or TPUs, please switch to JAX backend by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jax'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch to JAX backend\n",
    "bp.math.use_backend('jax')\n",
    "\n",
    "bp.math.get_backend_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In BrainPy, \"numpy\" and \"jax\" backends are interchangeable. Both backends have the same APIs, and same codes can run on both backends (except ``for ...`` and ``if ... else ...`` in JAX backend, we are trying to solve this problem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The APIs in ``brainpy.math`` module in each backend is much similar to APIs in original ``numpy``. The detailed comparison please see the [Comparison Table](../apis/math/comparison.rst). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the **array creation** functions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.],\n",
       "                      [0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.zeros((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[1, 2],\n",
       "                      [3, 4]], dtype=int32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = bp.math.array([[1,2], [3,4]])\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **array manipulation** functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(4, dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([1, 1, 2, 2, 3, 3, 4, 4], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.repeat(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[1, 1, 2, 2],\n",
       "                      [3, 3, 4, 4]], dtype=int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.repeat(x, 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **random numbers** generation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[0.84606385, 0.14539516, 0.98411   , 0.5173148 , 0.9132446 ],\n",
       "                      [0.39373338, 0.70007217, 0.524508  , 0.25626922, 0.9771589 ],\n",
       "                      [0.21962452, 0.14170194, 0.87090707, 0.31382847, 0.44447434]],            dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.random.random((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[ 2.7446158 , -0.86415875,  2.2743175 ,  0.87442636,\n",
       "                        3.4002311 ],\n",
       "                      [ 2.7979205 , -1.6518768 , -0.7373221 ,  0.7196598 ,\n",
       "                       -0.12697993]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = bp.math.random.normal(loc=0.0, scale=2.0, size=(2, 5))\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **linear algebra** functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([[ 8.340457 , -4.1679125,  0.7996733,  2.313746 ,  3.1462712],\n",
       "                      [19.42553  , -9.199984 ,  3.873664 ,  5.5019183,  9.692774 ]],            dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(JaxArray(DeviceArray([-0.37228107+0.j,  5.3722816 +0.j], dtype=complex64)),\n",
       " JaxArray(DeviceArray([[-0.8245648 +0.j, -0.41597357+0.j],\n",
       "                       [ 0.56576747+0.j, -0.9093767 +0.j]], dtype=complex64)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.linalg.eig(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **discrete fourier transform** functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([ 3.2584137e-07+3.1786513e-08j,  8.0000000e+00+4.8023384e-07j,\n",
       "                      -3.2584137e-07+3.1786513e-08j, -1.6858739e-07+3.1786506e-08j,\n",
       "                      -3.8941437e-07-2.0663207e-07j,  2.3841858e-07-1.9411573e-07j,\n",
       "                       3.8941437e-07-2.0663207e-07j,  1.6858739e-07+3.1786506e-08j],            dtype=complex64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.fft.fft(bp.math.exp(2j * bp.math.pi * bp.math.arange(8) / 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([ 1.+0.j,  0.+1.j, -1.+0.j,  0.-1.j], dtype=complex64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.math.fft.ifft(bp.math.array([0, 4, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full list of API implementation please see the [Comparison Table](../apis/math/comparison.rst)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JIT for Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take advantage of the JIT compilation, users just need to wrap their customized *functions* or *objects* into **[bp.math.jit()](../apis/math/generated/brainpy.math.numpy.jit.rst)** to instruct BrainPy to transform your codes into machine codes. \n",
    "\n",
    "\n",
    "Take the **pure functions** as the example. Here we try to implement a function of Gaussian Error Linear Unit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "  sqrt = bp.math.sqrt(2 / bp.math.pi)\n",
    "  cdf = 0.5 * (1.0 + bp.math.tanh(sqrt * (x + 0.044715 * (x ** 3))))\n",
    "  y = x * cdf\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 µs ± 1.36 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# jax backend, without JIT\n",
    "\n",
    "x = bp.math.random.random(100000)\n",
    "%timeit gelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.4 µs ± 901 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# jax backend, with JIT\n",
    "\n",
    "gelu_jit = bp.math.jit(gelu)\n",
    "%timeit gelu_jit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.math.use_backend('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.48 ms ± 17.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# numpy backend, without JIT\n",
    "\n",
    "x = bp.math.random.random(100000)\n",
    "%timeit gelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.88 ms ± 68.6 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# numpy backend, with JIT\n",
    "\n",
    "gelu_jit = bp.math.jit(gelu)\n",
    "%timeit gelu_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JIT for Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, in BrainPy, JIT compilation can be carried on the **class objects**. Specifically, any instance of [brainpy.Base](../apis/generated/brainpy.base.Base.rst) object can be just-in-time compiled into machine codes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a simple example, which trains a Logistic regression classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(bp.Base):\n",
    "    def __init__(self, dimension):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        # parameters    \n",
    "        self.dimension = dimension\n",
    "    \n",
    "        # variables\n",
    "        self.w = bp.math.Variable(2.0 * bp.math.ones(dimension) - 1.3)\n",
    "\n",
    "    def __call__(self, X, Y):\n",
    "        u = bp.math.dot(((1.0 / (1.0 + bp.math.exp(-Y * bp.math.dot(X, self.w))) - 1.0) * Y), X)\n",
    "        self.w[:] = self.w - u\n",
    "        \n",
    "\n",
    "num_dim, num_points = 10, 20000000\n",
    "num_iter = 30\n",
    "\n",
    "points = bp.math.random.random((num_points, num_dim))\n",
    "labels = bp.math.random.random(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model without jit used time 18.506070852279663 s\n"
     ]
    }
   ],
   "source": [
    "# numpy backend, without JIT\n",
    "\n",
    "lr1 = LogisticRegression(num_dim)\n",
    "lr1(points, labels)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for i in range(num_iter):\n",
    "    lr1(points, labels)\n",
    "\n",
    "print(f'Logistic Regression model without jit used time {time.time() - t0} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model with jit used time 11.58539867401123 s\n"
     ]
    }
   ],
   "source": [
    "# numpy backend, with JIT\n",
    "\n",
    "lr2 = LogisticRegression(num_dim)\n",
    "jit_lr2 = bp.math.jit(lr2)\n",
    "jit_lr2(points, labels)  # first call is the compiling\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(num_iter):\n",
    "    jit_lr2(points, labels)\n",
    "\n",
    "print(f'Logistic Regression model with jit used time {time.time() - t0} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model with jit+parallel used time 7.264842987060547 s\n"
     ]
    }
   ],
   "source": [
    "# numpy backend, with JIT + parallel\n",
    "\n",
    "lr3 = LogisticRegression(num_dim)\n",
    "jit_lr3 = bp.math.jit(lr3, parallel=True)\n",
    "jit_lr3(points, labels)  # first call is the compiling\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(num_iter):\n",
    "    jit_lr3(points, labels)\n",
    "\n",
    "print(f'Logistic Regression model with jit+parallel used time {time.time() - t0} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's worth noting here is that:\n",
    "\n",
    "1. The dynamically changed variable (weight ``w``) is marked as a **[bp.math.Variable](../apis/math/generated/brainpy.math.numpy.Variable.rst)** in `__init__()` function. \n",
    "2. The variable ``w``  is in-place updated with ``[:]`` indexing in `__call__()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above two things are all things that are *special* in the JIT compilation of class objects. Other operations and coding styles are the same with class objects without JIT acceleration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mechanism of JIT in NumPy backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, **why must we in-place update the dynamically changed variables?**\n",
    "\n",
    "- First of all, in the compilation phase, a ``self.`` accessed variable which is not an instance of ``bp.math.Variable`` will be compiled as a static constant. For example, ``self.a = 1.`` will be compiled as a constant ``1.``. If you try to change the value of ``self.a``, it will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "class Demo1(bp.Base):\n",
    "    def __init__(self):\n",
    "        super(Demo1, self).__init__()\n",
    "        \n",
    "        self.a = 1.\n",
    "    \n",
    "    def update(self, b):\n",
    "        self.a = b\n",
    "        \n",
    "\n",
    "d1 = Demo1()\n",
    "bp.math.jit(d1.update)(2.)\n",
    "print(d1.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second, all the variables you want to change during the function call must be labeled as ``bp.math.Variable``. Then during the JIT compilation period, these variables will be recompiled as arguments of the jitted functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recompiled function:\n",
      "-------------------------\n",
      "\n",
      "def update(b, Demo20_a=None):\n",
      "    Demo20_a = b\n",
      "\n",
      "\n",
      "The namespace of the above function:\n",
      "------------------------------------\n",
      "{}\n",
      "\n",
      "The recompiled function:\n",
      "-------------------------\n",
      "def new_update(b):\n",
      "  update(b, Demo20_a=Demo20.a.value,)\n",
      "\n",
      "The namespace of the above function:\n",
      "------------------------------------\n",
      "{'Demo20': <__main__.Demo2 object at 0x7ff00c1cba30>,\n",
      " 'update': CPUDispatcher(<function update at 0x7ff0200993a0>)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function new_update(b)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Demo2(bp.Base):\n",
    "    def __init__(self):\n",
    "        super(Demo2, self).__init__()\n",
    "        \n",
    "        self.a = bp.math.Variable(1.)\n",
    "    \n",
    "    def update(self, b):\n",
    "        self.a = b\n",
    "        \n",
    "\n",
    "bp.math.jit(Demo2().update, show_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original ``Demo2.update`` function is recompiled as ``update()`` function, with the dynamical variable ``a`` compiled as an argument ``Demo20_a``. Then, during the functional call (in the ``new_update()`` function), ``Demo20.a.value`` is passed to ``Demo20_a`` for the jitted ``update()`` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Third, as you can notice in the above source code of the recompiled function, the recompiled variable ``Demo20_a`` does not return. This means once the function finished running, the computed value will disappear. Therefore, the dynamically changed variables must be in-place updated to hold their updated values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(2.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Demo3(bp.Base):\n",
    "    def __init__(self):\n",
    "        super(Demo3, self).__init__()\n",
    "        \n",
    "        self.a = bp.math.Variable(1.)\n",
    "    \n",
    "    def update(self, b):\n",
    "        self.a[...] = b\n",
    "        \n",
    "\n",
    "d3 = Demo3()\n",
    "bp.math.jit(d3.update)(2.)\n",
    "d3.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above simple demonstrations illustrate the core mechanism of the JIT compilation in NumPy backend. [bp.math.jit()](../apis/math/generated/brainpy.math.numpy.jit.rst) in NumPy backend can recursively compile your class objects. So, please try you models, and run it under the JIT accelerations.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mechanism of JIT compilation of JAX backend is quite different. We will detail this in th upcoming tutorials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-place operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next, what's the most important question is: **what are in-place operators?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = bp.math.arange(10)\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, in-place operators include the following operations:\n",
    "\n",
    "1. **Indexing and slicing**. Like (More details please refer to [Array Objects Indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html))\n",
    "  - Index: ``v[i] = a``\n",
    "  - Slice: ``v[i:j] = b``\n",
    "  - Slice the specific values: ``v[[1, 3]] = c``\n",
    "  - Slice all values, ``v[:] = d``, ``v[...] = e``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0] = 1\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1: 2] = 1\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[[1, 3]] = 2\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:] = 0\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[...] = bp.math.arange(10)\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Augmented assignment**. All augmented assignment are in-place operations, which include \n",
    "  - ``+=`` (add)\n",
    "  - ``-=`` (subtract)\n",
    "  - ``/=`` (divide)\n",
    "  - ``*=`` (multiply)\n",
    "  - ``//=`` (floor divide)\n",
    "  - ``%=`` (modulo)\n",
    "  - ``**=`` (power)\n",
    "  - ``&=`` (and)\n",
    "  - ``|=`` (or)\n",
    "  - ``^=`` (xor)\n",
    "  - ``<<=`` (left shift)\n",
    "  - ``>>=`` (right shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v += 1\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v *= 2\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v |= bp.math.random.randint(0, 2, 10)\n",
    "\n",
    "id (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v **= 2.\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668971726128"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v >>= 2\n",
    "\n",
    "id(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced usage please see our forthcoming tutorials. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainpy",
   "language": "python",
   "name": "brainpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.76px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
