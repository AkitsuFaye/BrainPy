{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b37faba",
   "metadata": {},
   "source": [
    "# Build Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684bde1e",
   "metadata": {},
   "source": [
    "Artificial neural networks in BrainPy are used to build dynamical systems. Here we only talk about how to build a neural network and how to train it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be37bce",
   "metadata": {},
   "source": [
    "The [brainpy.simulation.layers](../apis/auto/training/layers.rst) module provides various classes representing the layers of a neural network. All of them are subclasses of the ``brainpy.training.layers.Module`` base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc48b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainpy as bp\n",
    "import brainpy.math as bm\n",
    "\n",
    "bp.math.set_platform('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b39935",
   "metadata": {},
   "source": [
    "## Creating a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d00efc",
   "metadata": {},
   "source": [
    "A layer can be created as an instance of a ``brainpy.training.layers.Module`` subclass. For example, a dense layer can be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9953d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = bp.layers.Dense(num_hidden=100, num_input=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4760090c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brainpy.training.layers.dense.Dense"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c628ad",
   "metadata": {},
   "source": [
    "This will create a dense layer with 100 units, connected to another input layer with 128 dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b266348",
   "metadata": {},
   "source": [
    "## Creating a network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b09f1",
   "metadata": {},
   "source": [
    "Chaining layer instances together like this will allow you to specify your desired network structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aee9ae",
   "metadata": {},
   "source": [
    "This can be done with inheritance  from ``brainpy.simulation.layers.Module``, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930010a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(bp.layers.Module):\n",
    "    def __init__(self, n_in, n_l1, n_l2, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.l1 = bp.layers.Dense(num_hidden=n_l1, num_input=n_in)\n",
    "        self.l2 = bp.layers.Dense(num_hidden=n_l2, num_input=n_l1)\n",
    "        self.l3 = bp.layers.Dense(num_hidden=n_out, num_input=n_l2)\n",
    "        \n",
    "    def update(self, x):\n",
    "        x = bm.relu(self.l1(x))\n",
    "        x = bm.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf84d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = MLP(10, 50, 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7012069",
   "metadata": {},
   "source": [
    "Or using ``brainpy.simulation.layers.Sequential``, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05843e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = bp.layers.Sequential(\n",
    "    l1=bp.layers.Dense(num_hidden=50, num_input=10),\n",
    "    r1=bp.layers.Activation('relu'), \n",
    "    l2=bp.layers.Dense(num_hidden=100, num_input=50),\n",
    "    r2=bp.layers.Activation('relu'), \n",
    "    l3=bp.layers.Dense(num_hidden=2, num_input=100),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21290a6",
   "metadata": {},
   "source": [
    "## Naming a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2332b7",
   "metadata": {},
   "source": [
    "For convenience, you can name a layer by specifying the name keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6c05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_hidden = bp.layers.Dense(num_hidden=50, num_input=10, name='hidden_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9466b3d3",
   "metadata": {},
   "source": [
    "## Initializing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121fd2e",
   "metadata": {},
   "source": [
    "Many types of layers, such as ``brainpy.simulation.layers.Dense``, have trainable parameters. These are referred to by short names that match the conventions used in modern deep learning literature. For example, a weight matrix will usually be called *w*, and a bias vector will usually be *b*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468f5be",
   "metadata": {},
   "source": [
    "When creating a layer with trainable parameters, ``TrainVar`` will be created for them and initialized automatically. You can optionally specify your own initialization strategy by using keyword arguments that match the parameter variable names. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9dc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = bp.layers.Dense(num_hidden=50, num_input=10, w=bp.init.Normal(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f18496",
   "metadata": {},
   "source": [
    "The weight matrix *w* of this dense layer will be initialized using samples from a normal distribution with standard deviation 0.01 (see [brainpy.initialize](../apis/auto/training/initialize.rst) for more information)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff18c3",
   "metadata": {},
   "source": [
    "There are several ways to manually initialize parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304a50d",
   "metadata": {},
   "source": [
    "- Tensors\n",
    "\n",
    "If a tensor variable instance is provided, this is used unchanged as the parameter variable. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34b1808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.training.layers.dense.Dense at 0x1b157eeca90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = bm.random.normal(0, 0.01, size=(10, 50))\n",
    "bp.layers.Dense(num_hidden=50, num_input=10, w=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873ec27",
   "metadata": {},
   "source": [
    "- callable\n",
    "\n",
    "If a callable is provided (e.g. a function or a ``brainpy.training.initialize.Initializer`` instance), the callable will be called with the desired shape to generate suitable initial parameter values. The variable is then initialized with those values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696bec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.training.layers.dense.Dense at 0x1b1606a4520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.layers.Dense(num_hidden=50, num_input=10, w=bp.initialize.Normal(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526a90f",
   "metadata": {},
   "source": [
    "Or, using a custom initialization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf48920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.training.layers.dense.Dense at 0x1b161763520>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_w(shape):\n",
    "    return bm.random.normal(0, 0.01, shape)\n",
    "\n",
    "bp.layers.Dense(num_hidden=50, num_input=10, w=init_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf53f0",
   "metadata": {},
   "source": [
    "Some types of parameter variables can also be set to ``None`` at initialization (e.g. biases). In that case, the parameter variable will be omitted. For example, creating a dense layer without biases is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e546749d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.training.layers.dense.Dense at 0x1b1606a4fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.layers.Dense(num_hidden=50, num_input=10, b=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837da715",
   "metadata": {},
   "source": [
    "## Setup a training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0224b355",
   "metadata": {},
   "source": [
    "Here, we show an example to  train MLP to classify the MNIST images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b03d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "num_train, num_test = X_train.shape[0], X_test.shape[0]\n",
    "num_dim = bp.tools.size2num(X_train.shape[1:])\n",
    "X_train = np.asarray(X_train.reshape((num_train, num_dim)) / 255.0, dtype=bm.float_)\n",
    "X_test = np.asarray(X_test.reshape((num_test, num_dim)) / 255.0, dtype=bm.float_)\n",
    "Y_train = np.asarray(Y_train.flatten(), dtype=bm.float_)\n",
    "Y_test = np.asarray(Y_test.flatten(), dtype=bm.float_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4314942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_in=num_dim, n_l1=256, n_l2=128, n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "172b9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = bm.optimizers.Momentum(lr=1e-3, train_vars=model.train_vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73884a88",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "gv = bm.grad(lambda X, Y: bm.losses.cross_entropy_loss(model(X), Y),\n",
    "             dyn_vars=model.vars(),\n",
    "             grad_vars=model.train_vars(),\n",
    "             return_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d6f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bm.jit\n",
    "@bm.function(nodes=(model, opt))\n",
    "def train(x, y):\n",
    "    grads, loss = gv(x, y)\n",
    "    opt.update(grads=grads)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6971ff43",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "predict = bm.jit(lambda X: bm.softmax(model(X)), dyn_vars=model.vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a0c47e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1  Train Loss 1.248  Test Accuracy 86.880\n",
      "Epoch    2  Train Loss 0.475  Test Accuracy 89.680\n",
      "Epoch    3  Train Loss 0.371  Test Accuracy 90.870\n",
      "Epoch    4  Train Loss 0.328  Test Accuracy 91.660\n",
      "Epoch    5  Train Loss 0.300  Test Accuracy 92.410\n",
      "Epoch    6  Train Loss 0.279  Test Accuracy 92.740\n",
      "Epoch    7  Train Loss 0.263  Test Accuracy 93.170\n",
      "Epoch    8  Train Loss 0.249  Test Accuracy 93.410\n",
      "Epoch    9  Train Loss 0.236  Test Accuracy 93.740\n",
      "Epoch   10  Train Loss 0.225  Test Accuracy 93.780\n",
      "Epoch   11  Train Loss 0.215  Test Accuracy 94.020\n",
      "Epoch   12  Train Loss 0.207  Test Accuracy 94.270\n",
      "Epoch   13  Train Loss 0.198  Test Accuracy 94.490\n",
      "Epoch   14  Train Loss 0.191  Test Accuracy 94.550\n",
      "Epoch   15  Train Loss 0.184  Test Accuracy 94.760\n",
      "Epoch   16  Train Loss 0.177  Test Accuracy 94.860\n",
      "Epoch   17  Train Loss 0.171  Test Accuracy 95.020\n",
      "Epoch   18  Train Loss 0.166  Test Accuracy 95.100\n",
      "Epoch   19  Train Loss 0.160  Test Accuracy 95.300\n",
      "Epoch   20  Train Loss 0.155  Test Accuracy 95.470\n",
      "Epoch   21  Train Loss 0.150  Test Accuracy 95.500\n",
      "Epoch   22  Train Loss 0.146  Test Accuracy 95.680\n",
      "Epoch   23  Train Loss 0.142  Test Accuracy 95.780\n",
      "Epoch   24  Train Loss 0.138  Test Accuracy 95.890\n",
      "Epoch   25  Train Loss 0.134  Test Accuracy 95.970\n",
      "Epoch   26  Train Loss 0.131  Test Accuracy 95.920\n",
      "Epoch   27  Train Loss 0.127  Test Accuracy 95.970\n",
      "Epoch   28  Train Loss 0.124  Test Accuracy 96.110\n",
      "Epoch   29  Train Loss 0.121  Test Accuracy 96.140\n",
      "Epoch   30  Train Loss 0.118  Test Accuracy 96.200\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_batch = 128\n",
    "for epoch in range(30):\n",
    "  # Train\n",
    "  loss = []\n",
    "  sel = np.arange(len(X_train))\n",
    "  np.random.shuffle(sel)\n",
    "  for it in range(0, X_train.shape[0], num_batch):\n",
    "    l = train(X_train[sel[it:it + num_batch]], Y_train[sel[it:it + num_batch]])\n",
    "    loss.append(l)\n",
    "\n",
    "  # Eval\n",
    "  test_predictions = predict(X_test).argmax(1)\n",
    "  accuracy = np.array(test_predictions).flatten() == Y_test\n",
    "  print(f'Epoch {epoch + 1:4d}  Train Loss {np.mean(loss):.3f}  Test Accuracy {100 * np.mean(accuracy):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainpy",
   "language": "python",
   "name": "brainpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
