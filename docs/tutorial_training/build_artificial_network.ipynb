{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b37faba",
   "metadata": {},
   "source": [
    "# Build Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684bde1e",
   "metadata": {},
   "source": [
    "Artificial neural networks in BrainPy are used to build dynamical systems. Here we only talk about how to build a neural network and how to train it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be37bce",
   "metadata": {},
   "source": [
    "The [brainpy.simulation.layers](../apis/simulation/layers.rst) module provides various classes representing the layers of a neural network. All of them are subclasses of the ``brainpy.simulation.layers.Module`` base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc48b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainpy as bp\n",
    "bp.set_platform('cpu')\n",
    "\n",
    "import brainpy.simulation.layers as nn\n",
    "import brainpy.math.jax as bm\n",
    "bp.math.use_backend('jax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b39935",
   "metadata": {},
   "source": [
    "## Creating a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d00efc",
   "metadata": {},
   "source": [
    "A layer can be created as an instance of a ``brainpy.layers.Module`` subclass. For example, a dense layer can be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9953d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.Dense(num_hidden=100, num_input=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4760090c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brainpy.simulation.layers.dense.Dense"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c628ad",
   "metadata": {},
   "source": [
    "This will create a dense layer with 100 units, connected to another input layer with 128 dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b266348",
   "metadata": {},
   "source": [
    "## Creating a network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b09f1",
   "metadata": {},
   "source": [
    "Chaining layer instances together like this will allow you to specify your desired network structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aee9ae",
   "metadata": {},
   "source": [
    "This can be done with inheritance  from ``brainpy.layers.Module``, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "930010a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_l1, n_l2, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Dense(num_hidden=n_l1, num_input=n_in)\n",
    "        self.l2 = nn.Dense(num_hidden=n_l2, num_input=n_l1)\n",
    "        self.l3 = nn.Dense(num_hidden=n_out, num_input=n_l2)\n",
    "        \n",
    "    def update(self, x):\n",
    "        x = bm.relu(self.l1(x))\n",
    "        x = bm.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf84d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = MLP(10, 50, 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7012069",
   "metadata": {},
   "source": [
    "Or using ``brainpy.layers.Sequential``, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05843e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = nn.Sequential(\n",
    "    l1=nn.Dense(num_hidden=50, num_input=10),\n",
    "    r1=nn.Activation('relu'), \n",
    "    l2=nn.Dense(num_hidden=100, num_input=50),\n",
    "    r2=nn.Activation('relu'), \n",
    "    l3=nn.Dense(num_hidden=2, num_input=100),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21290a6",
   "metadata": {},
   "source": [
    "## Naming a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2332b7",
   "metadata": {},
   "source": [
    "For convenience, you can name a layer by specifying the name keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6c05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_hidden = nn.Dense(num_hidden=50, num_input=10, name='hidden_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9466b3d3",
   "metadata": {},
   "source": [
    "## Initializing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121fd2e",
   "metadata": {},
   "source": [
    "Many types of layers, such as ``brainpy.layers.Dense``, have trainable parameters. These are referred to by short names that match the conventions used in modern deep learning literature. For example, a weight matrix will usually be called *w*, and a bias vector will usually be *b*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468f5be",
   "metadata": {},
   "source": [
    "When creating a layer with trainable parameters, ``TrainVar`` will be created for them and initialized automatically. You can optionally specify your own initialization strategy by using keyword arguments that match the parameter variable names. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9dc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.Dense(num_hidden=50, num_input=10, w=bp.initialize.Normal(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f18496",
   "metadata": {},
   "source": [
    "The weight matrix *w* of this dense layer will be initialized using samples from a normal distribution with standard deviation 0.01 (see [brainpy.initialize](../apis/simulation/initialize.rst) for more information)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff18c3",
   "metadata": {},
   "source": [
    "There are several ways to manually initialize parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304a50d",
   "metadata": {},
   "source": [
    "- Tensors\n",
    "\n",
    "If a tensor variable instance is provided, this is used unchanged as the parameter variable. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34b1808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.simulation.layers.dense.Dense at 0x23cff9bb910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = bm.random.normal(0, 0.01, size=(10, 50))\n",
    "nn.Dense(num_hidden=50, num_input=10, w=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873ec27",
   "metadata": {},
   "source": [
    "- callable\n",
    "\n",
    "If a callable is provided (e.g. a function or a ``brainpy.initialize.Initializer`` instance), the callable will be called with the desired shape to generate suitable initial parameter values. The variable is then initialized with those values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696bec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.simulation.layers.dense.Dense at 0x23cff9bf2b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Dense(num_hidden=50, num_input=10, w=bp.initialize.Normal(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526a90f",
   "metadata": {},
   "source": [
    "Or, using a custom initialization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf48920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.simulation.layers.dense.Dense at 0x23cff9ac670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_w(shape):\n",
    "    return bm.random.normal(0, 0.01, shape)\n",
    "\n",
    "nn.Dense(num_hidden=50, num_input=10, w=init_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf53f0",
   "metadata": {},
   "source": [
    "Some types of parameter variables can also be set to ``None`` at initialization (e.g. biases). In that case, the parameter variable will be omitted. For example, creating a dense layer without biases is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e546749d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brainpy.simulation.layers.dense.Dense at 0x23cff99fa30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Dense(num_hidden=50, num_input=10, b=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837da715",
   "metadata": {},
   "source": [
    "## Setup a training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0224b355",
   "metadata": {},
   "source": [
    "Here, we show an example to  train MLP to classify the MNIST images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b03d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "num_train, num_test = X_train.shape[0], X_test.shape[0]\n",
    "num_dim = bp.tools.size2num(X_train.shape[1:])\n",
    "X_train = np.asarray(X_train.reshape((num_train, num_dim)) / 255.0, dtype=bm.float_)\n",
    "X_test = np.asarray(X_test.reshape((num_test, num_dim)) / 255.0, dtype=bm.float_)\n",
    "Y_train = np.asarray(Y_train.flatten(), dtype=bm.float_)\n",
    "Y_test = np.asarray(Y_test.flatten(), dtype=bm.float_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4314942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_in=num_dim, n_l1=256, n_l2=128, n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "172b9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = bm.optimizers.Momentum(lr=1e-3, train_vars=model.train_vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73884a88",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "gv = bm.grad(lambda X, Y: bm.losses.cross_entropy_loss(model(X), Y),\n",
    "             dyn_vars=model.vars(),\n",
    "             grad_vars=model.train_vars(),\n",
    "             return_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2d6f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bm.jit\n",
    "@bm.function(nodes=(model, opt))\n",
    "def train(x, y):\n",
    "    grads, loss = gv(x, y)\n",
    "    opt.update(grads=grads)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6971ff43",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "predict = bm.jit(lambda X: bm.softmax(model(X)), dyn_vars=model.vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10a0c47e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1  Train Loss 1.212  Test Accuracy 86.410\n",
      "Epoch    2  Train Loss 0.467  Test Accuracy 89.810\n",
      "Epoch    3  Train Loss 0.367  Test Accuracy 90.670\n",
      "Epoch    4  Train Loss 0.325  Test Accuracy 91.470\n",
      "Epoch    5  Train Loss 0.298  Test Accuracy 92.220\n",
      "Epoch    6  Train Loss 0.278  Test Accuracy 92.890\n",
      "Epoch    7  Train Loss 0.261  Test Accuracy 93.140\n",
      "Epoch    8  Train Loss 0.248  Test Accuracy 93.530\n",
      "Epoch    9  Train Loss 0.235  Test Accuracy 93.810\n",
      "Epoch   10  Train Loss 0.224  Test Accuracy 94.010\n",
      "Epoch   11  Train Loss 0.214  Test Accuracy 94.100\n",
      "Epoch   12  Train Loss 0.205  Test Accuracy 94.350\n",
      "Epoch   13  Train Loss 0.196  Test Accuracy 94.540\n",
      "Epoch   14  Train Loss 0.189  Test Accuracy 94.680\n",
      "Epoch   15  Train Loss 0.182  Test Accuracy 94.910\n",
      "Epoch   16  Train Loss 0.175  Test Accuracy 95.070\n",
      "Epoch   17  Train Loss 0.169  Test Accuracy 95.190\n",
      "Epoch   18  Train Loss 0.163  Test Accuracy 95.280\n",
      "Epoch   19  Train Loss 0.157  Test Accuracy 95.410\n",
      "Epoch   20  Train Loss 0.153  Test Accuracy 95.570\n",
      "Epoch   21  Train Loss 0.148  Test Accuracy 95.760\n",
      "Epoch   22  Train Loss 0.143  Test Accuracy 95.760\n",
      "Epoch   23  Train Loss 0.139  Test Accuracy 95.930\n",
      "Epoch   24  Train Loss 0.135  Test Accuracy 95.910\n",
      "Epoch   25  Train Loss 0.131  Test Accuracy 96.150\n",
      "Epoch   26  Train Loss 0.128  Test Accuracy 96.110\n",
      "Epoch   27  Train Loss 0.124  Test Accuracy 96.310\n",
      "Epoch   28  Train Loss 0.121  Test Accuracy 96.330\n",
      "Epoch   29  Train Loss 0.118  Test Accuracy 96.410\n",
      "Epoch   30  Train Loss 0.115  Test Accuracy 96.410\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_batch = 128\n",
    "for epoch in range(30):\n",
    "  # Train\n",
    "  loss = []\n",
    "  sel = np.arange(len(X_train))\n",
    "  np.random.shuffle(sel)\n",
    "  for it in range(0, X_train.shape[0], num_batch):\n",
    "    l = train(X_train[sel[it:it + num_batch]], Y_train[sel[it:it + num_batch]])\n",
    "    loss.append(l)\n",
    "\n",
    "  # Eval\n",
    "  test_predictions = predict(X_test).argmax(1)\n",
    "  accuracy = np.array(test_predictions).flatten() == Y_test\n",
    "  print(f'Epoch {epoch + 1:4d}  Train Loss {np.mean(loss):.3f}  Test Accuracy {100 * np.mean(accuracy):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainpy",
   "language": "python",
   "name": "brainpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
