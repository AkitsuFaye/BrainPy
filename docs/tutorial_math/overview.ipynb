{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df2aeab",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d521c",
   "metadata": {},
   "source": [
    "@[Chaoming Wang](https://github.com/chaoming0625)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f81807",
   "metadata": {},
   "source": [
    "The core idea behind BrainPy is the Just-In-Time (JIT) compilation. JIT compilation enables your Python code to be compiled into machine code \"just-in-time\" for execution. Subsequently, such transformed code can run at native machine code speed!\n",
    "\n",
    "Excellent JIT compilers such as [JAX](https://github.com/google/jax) and [Numba](https://github.com/numba/numba) are provided in Python. However, they are designed to work only on pure Python functions. While, in computational neuroscience, most models have too many parameters and variables, it's hard to manage and control model logic by only using functions. On the contrary, object-oriented programming (OOP) based on ``class`` in Python will make your coding more readable, controlable, flexible and modular. Therefore, it is necessary to support JIT compilation on class objects for programming in brain modeling. \n",
    "\n",
    "In order to provide **a platform can satisfy the need of brain dynamics programming**, we provide [brainpy.math](../apis/math.rst) module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdb1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainpy as bp\n",
    "import brainpy.math as bm\n",
    "\n",
    "bp.math.set_platform('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f632f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6cc3d",
   "metadata": {},
   "source": [
    "## Why do you need ``brainpy.math`` module?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bff518",
   "metadata": {},
   "source": [
    "Specifically, ``brainpy.math`` make the following contributions:\n",
    "\n",
    "- **Numpy-like ndarray**. Python users are familiar with [NumPy](https://numpy.org/), especially its [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html). JAX has a similar ``ndarray`` and similar operations on JAX ndarray. However, several basic features are fundamentally different from numpy ndarray. For example, JAX ndarray does not support in-place mutating updates, like ``x[i] += y``. In order to overcome these gotchas, ``brainpy.math`` provides ``JaxArray``, which can be used as the same with numpy ndarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed3aff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ndarray in \"numpy\"\n",
    "\n",
    "a = np.arange(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f9cfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  2,  3,  4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0] += 10\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58daa91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([0, 1, 2, 3, 4], dtype=int32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ndarray in \"brainpy.math\"\n",
    "\n",
    "b = bm.arange(5)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2a1bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([10,  1,  2,  3,  4], dtype=int32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0] += 10\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c792b",
   "metadata": {},
   "source": [
    "More details please see [Tensors tutorial](./tensors.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627fd723",
   "metadata": {},
   "source": [
    "- **Numpy-like random sampling**. JAX has its own style to make random numbers, which is very different from the original NumPy. In order to provide a consistent experience, ``brainpy.math`` provides the same programming style for random sampling. There are minimal gaps between ``brainpy.math.random`` and ``numpy.random`` module. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca435e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling in \"numpy\"\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d166b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92961609, 0.31637555, 0.18391881, 0.20456028, 0.56772503,\n",
       "       0.5955447 , 0.96451452, 0.6531771 , 0.74890664, 0.65356987])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f71fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01437872, -2.59244222,  0.54998327,  0.45782576,  2.70583367,\n",
       "        1.77285868, -4.00327462, -0.74368507,  3.33805062, -0.87713947])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0., 2., 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdba27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling in \"brainpy.math.random\"\n",
    "\n",
    "bm.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb052e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([0.69164526, 0.21911383, 0.36975408, 0.3115406 , 0.7697315 ,\n",
       "                      0.01930189, 0.43002808, 0.7519586 , 0.01569903, 0.30688643],            dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63f7e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([ 2.9769602 , -3.2109535 ,  1.465871  ,  0.9005953 ,\n",
       "                       1.7705722 , -2.477971  , -1.8175219 ,  2.1754556 ,\n",
       "                      -0.25283262,  2.0693657 ], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.random.normal(0., 2., 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c82fddf",
   "metadata": {},
   "source": [
    "More details please see [Tensors tutorial](./tensors.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9e385",
   "metadata": {},
   "source": [
    "- **Transformation on class objects**. OOP is the essence of Python. However, JAX's excellent tranformations (like JIT compilatio) only support [pure functions](https://en.wikipedia.org/wiki/Pure_function). In order to make them work on object-oriented coding used in brain dynamics programming, ``brainpy.math`` extends JAX's transformations to be capable of performing on Python classess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082101e",
   "metadata": {},
   "source": [
    "Example 1: JIT compilation performed on class objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c377055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(bp.Base):\n",
    "    def __init__(self, dimension):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        # parameters    \n",
    "        self.dimension = dimension\n",
    "    \n",
    "        # variables\n",
    "        self.w = bm.Variable(2.0 * bm.ones(dimension) - 1.3)\n",
    "\n",
    "    def __call__(self, X, Y):\n",
    "        u = bm.dot(((1.0 / (1.0 + bm.exp(-Y * bm.dot(X, self.w))) - 1.0) * Y), X)\n",
    "        self.w[:] = self.w - u\n",
    "        \n",
    "num_dim, num_points = 10, 20000000\n",
    "points = bm.random.random((num_points, num_dim))\n",
    "labels = bm.random.random(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c423d55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 ms ± 25.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(num_dim)\n",
    "\n",
    "%timeit lr1(points, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0264f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 ms ± 9.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "lr2 = bm.jit(LogisticRegression(num_dim))\n",
    "\n",
    "%timeit lr2(points, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab89d89",
   "metadata": {},
   "source": [
    "Example 2: Autograd performed on variables of a class object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50fb3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(bp.Base):\n",
    "  def __init__(self, num_hidden, num_input, **kwargs):\n",
    "    super(Linear, self).__init__(**kwargs)\n",
    "\n",
    "    # parameters\n",
    "    self.num_input = num_input\n",
    "    self.num_hidden = num_hidden\n",
    "\n",
    "    # variables\n",
    "    self.w = bm.random.random((num_input, num_hidden))\n",
    "    self.b = bm.zeros((num_hidden,))\n",
    "\n",
    "  def __call__(self, x):\n",
    "    r = x @ self.w + self.b\n",
    "    return r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3996e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Linear(num_hidden=3, num_input=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad95c9ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(JaxArray(DeviceArray([[0.14844148, 0.14844148, 0.14844148],\n",
       "                       [0.2177031 , 0.2177031 , 0.2177031 ]], dtype=float32)),\n",
       " JaxArray(DeviceArray([0.33333334, 0.33333334, 0.33333334], dtype=float32)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.grad(l, grad_vars=(l.w, l.b))(bm.random.random([5, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f217b6",
   "metadata": {},
   "source": [
    "## What's the difference between ``brainpy.math`` and other frameworks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78647e8",
   "metadata": {},
   "source": [
    "``brainpy.math`` is not intended to be a reimplementation of the API of any other frameworks. All we are trying to do is to make **a better brain dynamics programming framework for Python users**. \n",
    "\n",
    "However, there are important differences between ``brainpy.math`` and other frameworks. \n",
    "\n",
    "Essentially, JAX itself and many other JAX frameworks follow a functional programming paradigm. When appling this kind of coding style on the brain dynamics models, it will be a difficult problem because many variables and parameter in a model will make the coding out of control. \n",
    "\n",
    "On the contrary, ``brainpy.math`` allows an object-oriented programming paradigm (which is much more Pythonic). The most similar framework is called [Objax](https://github.com/google/objax), which also supports OOP based on JAX. However, it is more suitable for deep learning domain, and can not be directly used in brain dynamics programming. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a00cad",
   "metadata": {},
   "source": [
    "## How to interoperate with other JAX frameworks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c73ac7",
   "metadata": {},
   "source": [
    "BrainPy can be easily interoperated with other JAX frameworks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f15c5",
   "metadata": {},
   "source": [
    "- First, **data can be exchangeable**. This is because ``JaxArray`` can direactly convert to JAX ndarray or NumPy ndarray.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7459094c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([10,  1,  2,  3,  4], dtype=int32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd6508",
   "metadata": {},
   "source": [
    "Convert ``JaxArray`` into a JAX ndarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a38327b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([10,  1,  2,  3,  4], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JaxArray.value is a JAX ndarray\n",
    "\n",
    "b.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882edee",
   "metadata": {},
   "source": [
    "Convert a ``JaxArray`` into a numpy ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01720ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  2,  3,  4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JaxArray can be easily converted to a numpy ndarray\n",
    "\n",
    "np.asarray(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1191e7",
   "metadata": {},
   "source": [
    "Convert a numpy ndarray into a ``JaxArray``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06e67706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([0, 1, 2, 3, 4], dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.asarray(np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f9317",
   "metadata": {},
   "source": [
    "Convert a JAX ndarray into a ``JaxArray``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f4b512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f03b6fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([0, 1, 2, 3, 4], dtype=int32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.asarray(jnp.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f11d43d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaxArray(DeviceArray([0, 1, 2, 3, 4], dtype=int32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.JaxArray(jnp.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5eb21d",
   "metadata": {},
   "source": [
    "- Second, **transformations in ``brainpy.math`` can also works on functions**. This means APIs in other JAX frameworks can be naturally integrated in BrainPy. Let's take the gradient-based optimisation library [Optax](https://github.com/deepmind/optax) as an example to illustrate how to use other JAX framework as our own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f99dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52731f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create several useful functions. \n",
    "\n",
    "network = bm.vmap(lambda params, x: bm.dot(params, x), in_axes=(None, 0))\n",
    "\n",
    "def compute_loss(params, x, y):\n",
    "  y_pred = network(params, x)\n",
    "  loss = bm.mean(optax.l2_loss(y_pred, y))\n",
    "  return loss\n",
    "\n",
    "@bm.jit\n",
    "def train(params, opt_state, xs, ys):\n",
    "  grads = bm.grad(compute_loss)(params, xs.value, ys)\n",
    "  updates, opt_state = optimizer.update(grads, opt_state)\n",
    "  params = optax.apply_updates(params, updates)\n",
    "  return params, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a630831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "\n",
    "bm.random.seed(42)\n",
    "target_params = 0.5\n",
    "xs = bm.random.normal(size=(16, 2))\n",
    "ys = bm.sum(xs * target_params, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2e02ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters of the model + optimizer\n",
    "\n",
    "params = bm.array([0.0, 0.0])\n",
    "optimizer = optax.adam(learning_rate=1e-1)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3761f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple update loop\n",
    "\n",
    "for _ in range(1000):\n",
    "  params, opt_state = train(params, opt_state, xs, ys)\n",
    "\n",
    "assert bm.allclose(params, target_params), \\\n",
    "  'Optimization should retrieve the target params used to generate the data.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainpy",
   "language": "python",
   "name": "brainpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
